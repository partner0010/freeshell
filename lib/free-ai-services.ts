/**
 * ì™„ì „ ë¬´ë£Œ AI ì„œë¹„ìŠ¤ í†µí•©
 * API í‚¤ ì—†ì´ë„ ì‘ë™í•˜ëŠ” ë¬´ë£Œ AI ì„œë¹„ìŠ¤ë“¤
 */

export interface FreeAIResponse {
  text: string;
  source: 'huggingface-public' | 'together-ai' | 'openrouter-free' | 'replicate-free' | 'groq-free' | 'cohere-free' | 'ai21-free' | 'perplexity-free' | 'ollama' | 'fallback';
  success: boolean;
  responseTime: number;
  requiresApiKey: boolean;
}

/**
 * ì™„ì „ ë¬´ë£Œ AI ì„œë¹„ìŠ¤ë¡œ í…ìŠ¤íŠ¸ ìƒì„±
 * ë¬´ë£Œ ìš°ì„  ì „ëµ: Groq > Ollama > Together > OpenRouter > HuggingFace > ê¸°íƒ€
 * ëª¨ë“  ì‚¬ëŒì´ ë¬´ë£Œë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ìµœì í™”
 */
export async function generateWithFreeAI(prompt: string): Promise<FreeAIResponse> {
  const startTime = Date.now();

  // 1ìˆœìœ„: Groq API (ë¬´ë£Œ í‹°ì–´, ë§¤ìš° ë¹ ë¦„, ìµœê³  í’ˆì§ˆ) âš¡
  // í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ì‚¬ìš© (í•„ìˆ˜)
  try {
    const groqKey = process.env.GROQ_API_KEY;
    if (groqKey && groqKey.trim() !== '') {
      const groqResponse = await tryGroqFree(prompt, groqKey);
      if (groqResponse.success) {
        console.log('[FreeAI] âœ… Groq API ì„±ê³µ (ìµœìš°ì„  ë¬´ë£Œ AI)');
        return {
          ...groqResponse,
          responseTime: Date.now() - startTime,
        };
      }
    }
  } catch (error) {
    console.warn('[FreeAI] Groq ì‹¤íŒ¨, ë‹¤ìŒ ì˜µì…˜ ì‹œë„:', error);
  }

  // 2ìˆœìœ„: Ollama ë¡œì»¬ LLM (ì™„ì „ ë¬´ë£Œ, ë¡œì»¬ ì‹¤í–‰) ğŸ 
  try {
    const ollamaResponse = await tryOllama(prompt);
    if (ollamaResponse.success) {
      console.log('[FreeAI] âœ… Ollama ë¡œì»¬ LLM ì„±ê³µ');
      return {
        ...ollamaResponse,
        responseTime: Date.now() - startTime,
      };
    }
  } catch (error) {
    console.warn('[FreeAI] Ollama ì‹¤íŒ¨, ë‹¤ìŒ ì˜µì…˜ ì‹œë„:', error);
  }

  // 3ìˆœìœ„: Together AI (ë¬´ë£Œ í‹°ì–´, API í‚¤ í•„ìš”í•˜ì§€ë§Œ ë¬´ë£Œ)
  try {
    const togetherKey = process.env.TOGETHER_API_KEY;
    if (togetherKey) {
      const togetherResponse = await tryTogetherAI(prompt, togetherKey);
      if (togetherResponse.success) {
        return {
          ...togetherResponse,
          responseTime: Date.now() - startTime,
        };
      }
    }
  } catch (error) {
    console.warn('[FreeAI] Together AI ì‹¤íŒ¨:', error);
  }

  // 4ìˆœìœ„: OpenRouter ë¬´ë£Œ ëª¨ë¸ (API í‚¤ í•„ìš”í•˜ì§€ë§Œ ë¬´ë£Œ)
  try {
    const openRouterKey = process.env.OPENROUTER_API_KEY;
    if (openRouterKey) {
      const openRouterResponse = await tryOpenRouterFree(prompt, openRouterKey);
      if (openRouterResponse.success) {
        return {
          ...openRouterResponse,
          responseTime: Date.now() - startTime,
        };
      }
    }
  } catch (error) {
    console.warn('[FreeAI] OpenRouter ì‹¤íŒ¨:', error);
  }

  // 5ìˆœìœ„: Hugging Face ê³µê°œ ëª¨ë¸ (API í‚¤ ì—†ì´ ì‚¬ìš© ê°€ëŠ¥)
  try {
    const hfResponse = await tryHuggingFacePublic(prompt);
    if (hfResponse.success) {
      return {
        ...hfResponse,
        responseTime: Date.now() - startTime,
      };
    }
  } catch (error) {
    console.warn('[FreeAI] Hugging Face ê³µê°œ ëª¨ë¸ ì‹¤íŒ¨:', error);
  }

  // 5ìˆœìœ„: Cohere (ë¬´ë£Œ í‹°ì–´)
  try {
    const cohereKey = process.env.COHERE_API_KEY;
    if (cohereKey) {
      const cohereResponse = await tryCohereFree(prompt, cohereKey);
      if (cohereResponse.success) {
        return {
          ...cohereResponse,
          responseTime: Date.now() - startTime,
        };
      }
    }
  } catch (error) {
    console.warn('[FreeAI] Cohere ì‹¤íŒ¨:', error);
  }

  // 6ìˆœìœ„: AI21 Labs (ë¬´ë£Œ í‹°ì–´)
  try {
    const ai21Key = process.env.AI21_API_KEY;
    if (ai21Key) {
      const ai21Response = await tryAI21Free(prompt, ai21Key);
      if (ai21Response.success) {
        return {
          ...ai21Response,
          responseTime: Date.now() - startTime,
        };
      }
    }
  } catch (error) {
    console.warn('[FreeAI] AI21 ì‹¤íŒ¨:', error);
  }

  // 7ìˆœìœ„: Perplexity (ë¬´ë£Œ í‹°ì–´)
  try {
    const perplexityKey = process.env.PERPLEXITY_API_KEY;
    if (perplexityKey) {
      const perplexityResponse = await tryPerplexityFree(prompt, perplexityKey);
      if (perplexityResponse.success) {
        return {
          ...perplexityResponse,
          responseTime: Date.now() - startTime,
        };
      }
    }
  } catch (error) {
    console.warn('[FreeAI] Perplexity ì‹¤íŒ¨:', error);
  }

  // 8ìˆœìœ„: Replicate ë¬´ë£Œ ëª¨ë¸ (ì¼ë¶€ ë¬´ë£Œ)
  try {
    const replicateKey = process.env.REPLICATE_API_TOKEN;
    if (replicateKey) {
      const replicateResponse = await tryReplicateFree(prompt, replicateKey);
      if (replicateResponse.success) {
        return {
          ...replicateResponse,
          responseTime: Date.now() - startTime,
        };
      }
    }
  } catch (error) {
    console.warn('[FreeAI] Replicate ì‹¤íŒ¨:', error);
  }

  // ìµœì¢… Fallback: ê·œì¹™ ê¸°ë°˜ ì‘ë‹µ
  return {
    text: generateIntelligentFallback(prompt),
    source: 'fallback',
    success: true,
    responseTime: Date.now() - startTime,
    requiresApiKey: false,
  };
}

/**
 * Hugging Face ê³µê°œ ëª¨ë¸ (API í‚¤ ì—†ì´ ì‚¬ìš© ê°€ëŠ¥)
 * ì—¬ëŸ¬ ê³µê°œ ëª¨ë¸ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„
 */
async function tryHuggingFacePublic(prompt: string): Promise<FreeAIResponse> {
  // ì—¬ëŸ¬ ê³µê°œ ëª¨ë¸ ì‹œë„ (ë” ì•ˆì •ì )
  const publicModels = [
    'microsoft/DialoGPT-medium',
    'gpt2',
    'distilgpt2',
  ];

  for (const model of publicModels) {
    try {
      const response = await fetch(
        `https://api-inference.huggingface.co/models/${model}`,
        {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            inputs: prompt,
            parameters: {
              max_length: 150,
              temperature: 0.7,
              return_full_text: false,
            },
          }),
        }
      );

      if (response.ok) {
        const data = await response.json();
        let generatedText = '';
        
        if (Array.isArray(data) && data[0]?.generated_text) {
          generatedText = data[0].generated_text;
        } else if (typeof data === 'object' && data.generated_text) {
          generatedText = data.generated_text;
        }
        
        if (generatedText && generatedText.trim()) {
          // ì›ë³¸ í”„ë¡¬í”„íŠ¸ ì œê±° (ì¼ë¶€ ëª¨ë¸ì€ í”„ë¡¬í”„íŠ¸ë¥¼ í¬í•¨í•¨)
          const cleanText = generatedText.replace(prompt, '').trim();
          if (cleanText) {
            return {
              text: cleanText,
              source: 'huggingface-public',
              success: true,
              responseTime: 0,
              requiresApiKey: false,
            };
          }
        }
      } else if (response.status === 503) {
        // ëª¨ë¸ì´ ë¡œë”© ì¤‘ì¼ ìˆ˜ ìˆìŒ, ë‹¤ìŒ ëª¨ë¸ ì‹œë„
        console.warn(`[FreeAI] Hugging Face ëª¨ë¸ ${model} ë¡œë”© ì¤‘, ë‹¤ìŒ ëª¨ë¸ ì‹œë„...`);
        continue;
      } else if (response.status === 429) {
        // Rate limit, ë‹¤ìŒ ëª¨ë¸ ì‹œë„
        console.warn(`[FreeAI] Hugging Face ëª¨ë¸ ${model} rate limit, ë‹¤ìŒ ëª¨ë¸ ì‹œë„...`);
        continue;
      }
    } catch (error) {
      console.warn(`[FreeAI] Hugging Face ëª¨ë¸ ${model} ì˜¤ë¥˜:`, error);
      continue;
    }
  }

  return {
    text: '',
    source: 'huggingface-public',
    success: false,
    responseTime: 0,
    requiresApiKey: false,
  };
}

/**
 * Together AI (ë¬´ë£Œ í‹°ì–´)
 * API í‚¤ í•„ìš”í•˜ì§€ë§Œ ë¬´ë£Œë¡œ ì‚¬ìš© ê°€ëŠ¥
 */
async function tryTogetherAI(prompt: string, apiKey: string): Promise<FreeAIResponse> {
  try {
    const response = await fetch('https://api.together.xyz/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'meta-llama/Llama-3-8b-chat-hf',
        messages: [{ role: 'user', content: prompt }],
        temperature: 0.7,
        max_tokens: 1000,
      }),
    });

    if (response.ok) {
      const data = await response.json();
      const text = data.choices?.[0]?.message?.content;
      if (text) {
        return {
          text,
          source: 'together-ai',
          success: true,
          responseTime: 0,
          requiresApiKey: true,
        };
      }
    }
  } catch (error) {
    console.warn('[FreeAI] Together AI ì˜¤ë¥˜:', error);
  }

  return {
    text: '',
    source: 'together-ai',
    success: false,
    responseTime: 0,
    requiresApiKey: true,
  };
}

/**
 * OpenRouter ë¬´ë£Œ ëª¨ë¸
 * ì¼ë¶€ ëª¨ë¸ì€ ë¬´ë£Œë¡œ ì‚¬ìš© ê°€ëŠ¥
 */
async function tryOpenRouterFree(prompt: string, apiKey: string): Promise<FreeAIResponse> {
  try {
    const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
        'HTTP-Referer': 'https://freeshell.co.kr',
        'X-Title': 'Shell AI Platform',
      },
      body: JSON.stringify({
        model: 'google/gemini-flash-1.5', // ë¬´ë£Œ ëª¨ë¸
        messages: [{ role: 'user', content: prompt }],
        temperature: 0.7,
        max_tokens: 1000,
      }),
    });

    if (response.ok) {
      const data = await response.json();
      const text = data.choices?.[0]?.message?.content;
      if (text) {
        return {
          text,
          source: 'openrouter-free',
          success: true,
          responseTime: 0,
          requiresApiKey: true,
        };
      }
    }
  } catch (error) {
    console.warn('[FreeAI] OpenRouter ì˜¤ë¥˜:', error);
  }

  return {
    text: '',
    source: 'openrouter-free',
    success: false,
    responseTime: 0,
    requiresApiKey: true,
  };
}

/**
 * Groq API (ë¬´ë£Œ í‹°ì–´, ë§¤ìš° ë¹ ë¦„) âš¡ ìµœìš°ì„  ë¬´ë£Œ AI
 * ë¬´ë£Œë¡œ ë§¤ìš° ë¹ ë¥¸ ì‘ë‹µ ì œê³µ, GPT/Gemini ìˆ˜ì¤€ì˜ í’ˆì§ˆ
 */
async function tryGroqFree(prompt: string, apiKey: string): Promise<FreeAIResponse> {
  try {
    // ì—¬ëŸ¬ ëª¨ë¸ ì‹œë„ (ê°€ì¥ ì¢‹ì€ ëª¨ë¸ë¶€í„°)
    const models = [
      'llama-3.1-70b-versatile', // ìµœê³  í’ˆì§ˆ
      'llama-3.1-8b-instant',    // ë¹ ë¥¸ ì‘ë‹µ
      'mixtral-8x7b-32768',       // ëŒ€ìš©ëŸ‰ ì»¨í…ìŠ¤íŠ¸
      'gemma-7b-it',              // Google Gemma
    ];

    for (const model of models) {
      try {
        const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${apiKey}`,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            model: model,
            messages: [{ role: 'user', content: prompt }],
            temperature: 0.7,
            max_tokens: 4000, // ë” ê¸´ ì‘ë‹µ ê°€ëŠ¥
          }),
        });

        if (response.ok) {
          const data = await response.json();
          const text = data.choices?.[0]?.message?.content;
          if (text && text.trim()) {
            console.log(`[FreeAI] âœ… Groq API ì„±ê³µ (ëª¨ë¸: ${model})`);
            return {
              text,
              source: 'groq-free',
              success: true,
              responseTime: 0,
              requiresApiKey: true,
            };
          }
        } else if (response.status === 429) {
          // Rate limit, ë‹¤ìŒ ëª¨ë¸ ì‹œë„
          console.warn(`[FreeAI] Groq ëª¨ë¸ ${model} rate limit, ë‹¤ìŒ ëª¨ë¸ ì‹œë„...`);
          continue;
        }
      } catch (error) {
        console.warn(`[FreeAI] Groq ëª¨ë¸ ${model} ì˜¤ë¥˜:`, error);
        continue;
      }
    }
  } catch (error) {
    console.warn('[FreeAI] Groq ì „ì²´ ì˜¤ë¥˜:', error);
  }

  return {
    text: '',
    source: 'groq-free',
    success: false,
    responseTime: 0,
    requiresApiKey: true,
  };
}

/**
 * Ollama ë¡œì»¬ LLM (ì™„ì „ ë¬´ë£Œ, ë¡œì»¬ ì‹¤í–‰) ğŸ 
 * ì‚¬ìš©ì PCì—ì„œ ì§ì ‘ ì‹¤í–‰, ì™„ì „ ë¬´ë£Œ, í”„ë¼ì´ë²„ì‹œ ë³´ì¥
 * GPT/Gemini ìˆ˜ì¤€ì˜ í’ˆì§ˆì„ ë¬´ë£Œë¡œ ì œê³µ
 */
export async function tryOllama(prompt: string): Promise<FreeAIResponse> {
  // OllamaëŠ” ê¸°ë³¸ì ìœ¼ë¡œ localhost:11434ì—ì„œ ì‹¤í–‰
  const ollamaUrl = process.env.OLLAMA_URL || 'http://localhost:11434';
  
  // ì—¬ëŸ¬ ëª¨ë¸ ì‹œë„ (ì‚¬ìš©ìê°€ ì„¤ì¹˜í•œ ëª¨ë¸ ì¤‘ ì‚¬ìš© ê°€ëŠ¥í•œ ê²ƒ)
  // llama3.1:8b ê°™ì€ ë³€í˜•ë„ ì¸ì‹í•˜ë„ë¡ êµ¬ì²´ì ì¸ ì´ë¦„ ìš°ì„  ì‹œë„
  const models = [
    'llama3.1:8b',   // LLaMA 3.1 8B (ê°€ì¥ ë¹ ë¥´ê³  ì¢‹ìŒ) â­
    'llama3.1:70b',  // LLaMA 3.1 70B (ìµœê³  í’ˆì§ˆ)
    'llama3.1',      // LLaMA 3.1 (ê¸°ë³¸)
    'llama3:8b',     // LLaMA 3 8B
    'llama3',        // LLaMA 3
    'mistral',       // Mistral 7B
    'gemma:2b',      // Google Gemma 2B
    'gemma:7b',      // Google Gemma 7B
    'gemma',         // Google Gemma (ê¸°ë³¸)
    'phi3',          // Phi-3
    'llama2',        // LLaMA 2
  ];

  for (const model of models) {
    try {
      const response = await fetch(`${ollamaUrl}/api/generate`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: model,
          prompt: prompt,
          stream: false,
          options: {
            temperature: 0.7,
            num_predict: 2000,
          },
        }),
        signal: AbortSignal.timeout(30000), // 30ì´ˆ íƒ€ì„ì•„ì›ƒ
      });

      if (response.ok) {
        const data = await response.json();
        const text = data.response || '';
        if (text && text.trim()) {
          console.log(`[FreeAI] âœ… Ollama ë¡œì»¬ LLM ì„±ê³µ (ëª¨ë¸: ${model})`);
          return {
            text: text.trim(),
            source: 'ollama',
            success: true,
            responseTime: data.total_duration ? data.total_duration / 1000000000 : 0,
            requiresApiKey: false, // ì™„ì „ ë¬´ë£Œ, API í‚¤ ë¶ˆí•„ìš”
          };
        }
      } else if (response.status === 404) {
        // ëª¨ë¸ì´ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ, ë‹¤ìŒ ëª¨ë¸ ì‹œë„
        console.warn(`[FreeAI] Ollama ëª¨ë¸ ${model}ì´ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ, ë‹¤ìŒ ëª¨ë¸ ì‹œë„...`);
        continue;
      }
    } catch (error: any) {
      // ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ëŠ” Ollamaê°€ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŒ
      if (error.name === 'AbortError' || error.message?.includes('fetch')) {
        console.warn(`[FreeAI] Ollama ì—°ê²° ì‹¤íŒ¨ (Ollamaê°€ ì„¤ì¹˜/ì‹¤í–‰ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŒ): ${model}`);
        // Ollamaê°€ ì—†ìœ¼ë©´ ë‹¤ìŒ ì˜µì…˜ìœ¼ë¡œ ë„˜ì–´ê°
        break;
      }
      console.warn(`[FreeAI] Ollama ëª¨ë¸ ${model} ì˜¤ë¥˜:`, error);
      continue;
    }
  }

  return {
    text: '',
    source: 'ollama',
    success: false,
    responseTime: 0,
    requiresApiKey: false,
  };
}

/**
 * Cohere (ë¬´ë£Œ í‹°ì–´)
 * ë¬´ë£Œë¡œ í…ìŠ¤íŠ¸ ìƒì„± ì œê³µ
 */
async function tryCohereFree(prompt: string, apiKey: string): Promise<FreeAIResponse> {
  try {
    const response = await fetch('https://api.cohere.ai/v1/generate', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'command',
        prompt: prompt,
        max_tokens: 1000,
        temperature: 0.7,
      }),
    });

    if (response.ok) {
      const data = await response.json();
      const text = data.generations?.[0]?.text;
      if (text) {
        return {
          text,
          source: 'cohere-free',
          success: true,
          responseTime: 0,
          requiresApiKey: true,
        };
      }
    }
  } catch (error) {
    console.warn('[FreeAI] Cohere ì˜¤ë¥˜:', error);
  }

  return {
    text: '',
    source: 'cohere-free',
    success: false,
    responseTime: 0,
    requiresApiKey: true,
  };
}

/**
 * AI21 Labs (ë¬´ë£Œ í‹°ì–´)
 * ë¬´ë£Œë¡œ í…ìŠ¤íŠ¸ ìƒì„± ì œê³µ
 */
async function tryAI21Free(prompt: string, apiKey: string): Promise<FreeAIResponse> {
  try {
    const response = await fetch('https://api.ai21.com/studio/v1/j2-mid/complete', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        prompt: prompt,
        maxTokens: 1000,
        temperature: 0.7,
      }),
    });

    if (response.ok) {
      const data = await response.json();
      const text = data.completions?.[0]?.data?.text;
      if (text) {
        return {
          text,
          source: 'ai21-free',
          success: true,
          responseTime: 0,
          requiresApiKey: true,
        };
      }
    }
  } catch (error) {
    console.warn('[FreeAI] AI21 ì˜¤ë¥˜:', error);
  }

  return {
    text: '',
    source: 'ai21-free',
    success: false,
    responseTime: 0,
    requiresApiKey: true,
  };
}

/**
 * Perplexity (ë¬´ë£Œ í‹°ì–´)
 * ê²€ìƒ‰ ê¸°ë°˜ AI ì‘ë‹µ ì œê³µ
 */
async function tryPerplexityFree(prompt: string, apiKey: string): Promise<FreeAIResponse> {
  try {
    const response = await fetch('https://api.perplexity.ai/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'llama-3.1-sonar-small-128k-online',
        messages: [{ role: 'user', content: prompt }],
        temperature: 0.7,
        max_tokens: 1000,
      }),
    });

    if (response.ok) {
      const data = await response.json();
      const text = data.choices?.[0]?.message?.content;
      if (text) {
        return {
          text,
          source: 'perplexity-free',
          success: true,
          responseTime: 0,
          requiresApiKey: true,
        };
      }
    }
  } catch (error) {
    console.warn('[FreeAI] Perplexity ì˜¤ë¥˜:', error);
  }

  return {
    text: '',
    source: 'perplexity-free',
    success: false,
    responseTime: 0,
    requiresApiKey: true,
  };
}

/**
 * Replicate ë¬´ë£Œ ëª¨ë¸
 */
async function tryReplicateFree(prompt: string, apiKey: string): Promise<FreeAIResponse> {
  try {
    // ReplicateëŠ” ì£¼ë¡œ ì´ë¯¸ì§€ ìƒì„±ì— íŠ¹í™”ë˜ì–´ ìˆì–´ í…ìŠ¤íŠ¸ ìƒì„±ì—ëŠ” ì œí•œì 
    // ëŒ€ì‹  ë‹¤ë¥¸ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©
    return {
      text: '',
      source: 'replicate-free',
      success: false,
      responseTime: 0,
      requiresApiKey: true,
    };
  } catch (error) {
    console.warn('[FreeAI] Replicate ì˜¤ë¥˜:', error);
    return {
      text: '',
      source: 'replicate-free',
      success: false,
      responseTime: 0,
      requiresApiKey: true,
    };
  }
}

/**
 * ê·œì¹™ ê¸°ë°˜ ì§€ëŠ¥í˜• ì‘ë‹µ ìƒì„±
 */
function generateIntelligentFallback(prompt: string): string {
  const lowerPrompt = prompt.toLowerCase();
  
  // ì§ˆë¬¸ íŒ¨í„´ ê°ì§€
  if (lowerPrompt.includes('?') || 
      lowerPrompt.includes('ë¬´ì—‡') || 
      lowerPrompt.includes('ì–´ë–»ê²Œ') || 
      lowerPrompt.includes('ì™œ') ||
      lowerPrompt.includes('what') || 
      lowerPrompt.includes('how') || 
      lowerPrompt.includes('why')) {
    return generateQuestionResponse(prompt);
  }
  
  // ë²ˆì—­ ìš”ì²­
  if (lowerPrompt.includes('ë²ˆì—­') || 
      lowerPrompt.includes('translate')) {
    return generateTranslationResponse(prompt);
  }
  
  // ê²€ìƒ‰/ì •ë³´ ìš”ì²­
  if (lowerPrompt.includes('ê²€ìƒ‰') || 
      lowerPrompt.includes('ì•Œë ¤') || 
      lowerPrompt.includes('ì •ë³´') ||
      lowerPrompt.includes('search') || 
      lowerPrompt.includes('tell me') || 
      lowerPrompt.includes('about')) {
    return generateSearchResponse(prompt);
  }
  
  // ê¸°ë³¸ ì‘ë‹µ
  return generateDefaultResponse(prompt);
}

function generateQuestionResponse(prompt: string): string {
  return `# ${prompt}ì— ëŒ€í•œ ë‹µë³€

## ê°œìš”
${prompt}ì— ëŒ€í•´ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

## ì£¼ìš” ë‚´ìš©
ì´ ì£¼ì œì— ëŒ€í•œ ìƒì„¸í•œ ì •ë³´ì™€ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.

## ê²°ë¡ 
ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•˜ì‹œë©´ ë” êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.

---
*ì´ ì‘ë‹µì€ ê¸°ë³¸ AI ì—”ì§„ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ë” ì •í™•í•œ ë‹µë³€ì„ ì›í•˜ì‹œë©´ GOOGLE_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.*`;
}

function generateTranslationResponse(prompt: string): string {
  // ë²ˆì—­ ìš”ì²­ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
  const textMatch = prompt.match(/ë²ˆì—­[:\s]+(.+)/i) || prompt.match(/translate[:\s]+(.+)/i);
  const textToTranslate = textMatch ? textMatch[1].trim() : prompt;
  
  return `# ë²ˆì—­ ê²°ê³¼

**ì›ë¬¸**: ${textToTranslate}

**ë²ˆì—­**: ${textToTranslate}

---
*ê¸°ë³¸ ë²ˆì—­ ê¸°ëŠ¥ì…ë‹ˆë‹¤. ë” ì •í™•í•œ ë²ˆì—­ì„ ì›í•˜ì‹œë©´ GOOGLE_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.*`;
}

function generateSearchResponse(prompt: string): string {
  return `# ${prompt}ì— ëŒ€í•œ ì •ë³´

## ê²€ìƒ‰ ê²°ê³¼
${prompt}ì— ëŒ€í•œ ê´€ë ¨ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ìƒì„¸ ë‚´ìš©
ì´ ì£¼ì œì— ëŒ€í•œ í¬ê´„ì ì¸ ì •ë³´ì™€ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.

---
*ê¸°ë³¸ ê²€ìƒ‰ ê¸°ëŠ¥ì…ë‹ˆë‹¤. ë” ì •í™•í•œ ì •ë³´ë¥¼ ì›í•˜ì‹œë©´ GOOGLE_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.*`;
}

function generateDefaultResponse(prompt: string): string {
  return `# ${prompt}ì— ëŒ€í•œ ì‘ë‹µ

${prompt}ì— ëŒ€í•œ ì •ë³´ì™€ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.

## ì£¼ìš” í¬ì¸íŠ¸
- ê´€ë ¨ ì •ë³´ ì œê³µ
- ìƒì„¸ ë¶„ì„
- ì‹¤ìš©ì ì¸ í™œìš© ë°©ë²•

---
*ê¸°ë³¸ AI ì‘ë‹µì…ë‹ˆë‹¤. ë” ì •í™•í•œ ì‘ë‹µì„ ì›í•˜ì‹œë©´ GOOGLE_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.*`;
}
